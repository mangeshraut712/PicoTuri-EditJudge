# R1: Embedding Choice vs Accuracy/Latency
# e5-small-v2 + CLIP ViT-L/14 High Performance

experiment:
  name: "r1_e5_clip_l14"
  description: "e5-small-v2 text encoder + CLIP ViT-L/14 image encoder for higher accuracy"
  type: "r1_embeddings"
  
models:
  text_encoder:
    name: "intfloat/e5-small-v2"
    type: "e5"
    max_length: 512
    hidden_size: 384
    pooling: "mean"
    
  image_encoder:
    name: "open_clip/ViT-L-14"
    type: "clip"
    pretrained: "laion2b_s32b_b82k"
    image_size: 224
    hidden_size: 768
    
  fusion_head:
    input_dim: 1152  # 384 (text) + 768 (image)
    hidden_dims: [512, 256, 128]
    output_dim: 1
    dropout: 0.1
    activation: "gelu"
    
features:
  text_embedding: true
  image_embedding: true
  cross_modal_similarity: true
  image_similarity: true
  delta_features: false
  
training:
  batch_size: 24  # Smaller batch due to larger models
  learning_rate: 1e-4
  weight_decay: 0.01
  epochs: 10
  warmup_steps: 1000
  max_steps: 10000
  gradient_clip_norm: 1.0
  seeds: [42, 43, 44]
  
  optimizer:
    type: "adamw"
    betas: [0.9, 0.999]
    eps: 1e-8
    
  scheduler:
    type: "linear"
    warmup_ratio: 0.1
    
  data:
    train_split: 0.8
    val_split: 0.1
    test_split: 0.1
    shuffle: true
    num_workers: 4
    
evaluation:
  metrics: ["auc", "f1", "accuracy", "precision", "recall", "latency_p50", "latency_p95", "throughput", "model_size"]
  platforms: ["cpu", "cuda", "mps"]
  batch_sizes: [1, 4, 8, 16]
  
  calibration:
    method: "platt_scaling"
    validation_split: 0.2
    
performance:
  target_latency_p95_ms: 150  # Higher target due to larger models
  target_throughput_img_per_sec: 8
  max_model_size_mb: 800
  
hardware:
  gpu_memory_gb: 12  # Higher requirement for larger models
  cpu_cores: 4
  memory_gb: 16
  
output:
  save_model: true
  save_checkpoints: true
  export_onnx: true
  export_coreml: false
  
logging:
  level: "INFO"
  save_logs: true
  tensorboard: true
