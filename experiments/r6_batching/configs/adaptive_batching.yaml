# R6: Real-time Batching & Quantization
# Adaptive Micro-batching with INT8 Quantization

experiment:
  name: "r6_adaptive_batching"
  description: "Adaptive micro-batching with INT8 quantization for high throughput"
  type: "r6_batching"
  
models:
  text_encoder:
    name: "bert-base-uncased"
    type: "bert"
    max_length: 512
    hidden_size: 768
    pooling: "mean"
    
  image_encoder:
    name: "open_clip/ViT-B-32"
    type: "clip"
    pretrained: "laion2b_s34b_b79k"
    image_size: 224
    hidden_size: 512
    
  fusion_head:
    input_dim: 1280  # 768 (text) + 512 (image)
    hidden_dims: [512, 256, 128]
    output_dim: 1
    dropout: 0.1
    activation: "gelu"
    
features:
  text_embedding: true
  image_embedding: true
  cross_modal_similarity: true
  image_similarity: true
  delta_features: false
  
batching:
  strategy: "adaptive"
  min_batch_size: 1
  max_batch_size: 32
  target_latency_ms: 50
  max_wait_time_ms: 20
  window_size_ms: 10
  
quantization:
  enabled: true
  method: "dynamic_int8"
  quantize_text_encoder: false
  quantize_image_encoder: false
  quantize_fusion_head: true
  calibration_samples: 1000
  
training:
  batch_size: 32
  learning_rate: 1e-4
  weight_decay: 0.01
  epochs: 10
  warmup_steps: 1000
  max_steps: 10000
  gradient_clip_norm: 1.0
  seeds: [42, 43, 44]
  
  optimizer:
    type: "adamw"
    betas: [0.9, 0.999]
    eps: 1e-8
    
  scheduler:
    type: "linear"
    warmup_ratio: 0.1
    
  data:
    train_split: 0.8
    val_split: 0.1
    test_split: 0.1
    shuffle: true
    num_workers: 4
    
evaluation:
  metrics: ["auc", "f1", "accuracy", "throughput", "latency_p50", "latency_p95", "latency_p99", "memory_usage"]
  platforms: ["cpu", "cuda", "mps"]
  batch_sizes: [1, 2, 4, 8, 16, 32]
  
  load_testing:
    concurrent_requests: [1, 5, 10, 20, 50]
    duration_seconds: 60
    ramp_up_seconds: 10
    
performance:
  target_latency_p95_ms: 50
  target_throughput_img_per_sec: 30
  max_model_size_mb: 300
  target_memory_usage_mb: 1000
  
hardware:
  gpu_memory_gb: 8
  cpu_cores: 8
  memory_gb: 16
  
runtime:
  session_pool_size: 4
  warm_up_sessions: true
  enable_monitoring: true
  
output:
  save_model: true
  save_checkpoints: true
  export_onnx: true
  export_quantized: true
  
logging:
  level: "INFO"
  save_logs: true
  tensorboard: true
  detailed_metrics: true
