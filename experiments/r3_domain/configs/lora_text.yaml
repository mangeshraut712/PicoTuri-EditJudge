# R3: Domain Adaptation
# LoRA on Text Encoder for Domain-specific Fine-tuning

experiment:
  name: "r3_lora_text"
  description: "LoRA adapters on text encoder for domain-specific fine-tuning"
  type: "r3_domain"
  
models:
  text_encoder:
    name: "bert-base-uncased"
    type: "bert"
    max_length: 512
    hidden_size: 768
    pooling: "mean"
    
  image_encoder:
    name: "open_clip/ViT-B-32"
    type: "clip"
    pretrained: "laion2b_s34b_b79k"
    image_size: 224
    hidden_size: 512
    
  fusion_head:
    input_dim: 1280  # 768 (text) + 512 (image)
    hidden_dims: [512, 256, 128]
    output_dim: 1
    dropout: 0.1
    activation: "gelu"
    
domain_adaptation:
  method: "lora"
  target_modules: ["text_encoder"]
  lora_config:
    rank: 16
    alpha: 32
    dropout: 0.1
    target_layers: ["query", "value", "dense"]
  
  domain: "product_photos"
  adaptation_data_size: 1000
  validation_split: 0.2
  
  training:
    learning_rate: 1e-4
    batch_size: 16
    epochs: 5
    warmup_steps: 100
    
features:
  text_embedding: true
  image_embedding: true
  cross_modal_similarity: true
  image_similarity: true
  delta_features: false
  
training:
  batch_size: 32
  learning_rate: 1e-4
  weight_decay: 0.01
  epochs: 10
  warmup_steps: 1000
  max_steps: 10000
  gradient_clip_norm: 1.0
  seeds: [42, 43, 44]
  
  optimizer:
    type: "adamw"
    betas: [0.9, 0.999]
    eps: 1e-8
    
  scheduler:
    type: "linear"
    warmup_ratio: 0.1
    
  data:
    train_split: 0.8
    val_split: 0.1
    test_split: 0.1
    shuffle: true
    num_workers: 4
    
evaluation:
  metrics: ["auc", "f1", "accuracy", "delta_auc", "delta_f1", "generalization_gap"]
  platforms: ["cpu", "cuda", "mps"]
  
  domain_split:
    in_domain_test: true
    out_of_domain_test: true
    target_domains: ["product_photos", "portraits", "landscapes"]
    
performance:
  target_latency_p95_ms: 60
  target_throughput_img_per_sec: 15
  max_model_size_mb: 200
  
hardware:
  gpu_memory_gb: 8
  cpu_cores: 4
  memory_gb: 16
  
output:
  save_model: true
  save_adapters: true
  export_onnx: true
  
logging:
  level: "INFO"
  save_logs: true
  tensorboard: true
